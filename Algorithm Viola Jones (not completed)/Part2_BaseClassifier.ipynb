{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6719df6f-45ae-43ea-a5a1-34a1c73a5612",
      "metadata": {
        "tags": [],
        "id": "6719df6f-45ae-43ea-a5a1-34a1c73a5612"
      },
      "source": [
        "## Продолжаем реализовывать алгоритм Виолы-Джонса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00233210-e617-4f47-9196-7c241fcb1389",
      "metadata": {
        "id": "00233210-e617-4f47-9196-7c241fcb1389"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import _pickle as pickle\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "173fb172-8dae-4097-8ce2-69f07f302849",
      "metadata": {
        "id": "173fb172-8dae-4097-8ce2-69f07f302849"
      },
      "outputs": [],
      "source": [
        "with open('positive_data.pkl', 'rb') as f:\n",
        "    positive_features_full = pickle.load(f)\n",
        "\n",
        "with open('negative_data.pkl', 'rb') as f:\n",
        "    negative_features_full = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c68f0d9-f158-49a3-9297-83b811ddbcf6",
      "metadata": {
        "tags": [],
        "id": "0c68f0d9-f158-49a3-9297-83b811ddbcf6"
      },
      "source": [
        "## Подготовим тренировочный набор"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbcf799f-1ea8-4f08-aa82-f4de3ea02e03",
      "metadata": {
        "id": "cbcf799f-1ea8-4f08-aa82-f4de3ea02e03"
      },
      "source": [
        "Ограничим количество примеров пока модель не начнет учиться"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8062193-b2a6-4bf3-8c7e-e5cc46a6c77c",
      "metadata": {
        "id": "f8062193-b2a6-4bf3-8c7e-e5cc46a6c77c"
      },
      "outputs": [],
      "source": [
        "objects_count = 500\n",
        "\n",
        "# objects_count = None  снимите ограничение для достижения лучших результатов\n",
        "\n",
        "\n",
        "positive_features = positive_features_full[:objects_count]\n",
        "negative_features = negative_features_full[:objects_count]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34eba136-f868-433d-aca4-538e6ba5196d",
      "metadata": {
        "id": "34eba136-f868-433d-aca4-538e6ba5196d"
      },
      "outputs": [],
      "source": [
        "y_positive = np.ones(len(positive_features))\n",
        "y_negative = np.zeros(len(negative_features))\n",
        "\n",
        "X = np.concatenate((positive_features, negative_features))\n",
        "y = np.concatenate((y_positive, y_negative))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d245f10e-5bc7-49dc-a881-047b58827393",
      "metadata": {
        "id": "d245f10e-5bc7-49dc-a881-047b58827393"
      },
      "source": [
        "Разделим выборку на обучающую и тестовую"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "271e4aec-ed93-45e5-b5a5-c1a411ddd70b",
      "metadata": {
        "id": "271e4aec-ed93-45e5-b5a5-c1a411ddd70b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23728605-c46a-4200-b34b-2a8dad704723",
      "metadata": {
        "id": "23728605-c46a-4200-b34b-2a8dad704723"
      },
      "source": [
        "## Базовый классификатор\n",
        "\n",
        "В качестве базового классификатора мы будем использовать \"решающий пень\" (decision stump)\n",
        "Decision stump -- это минимально возможное решающее дерево, имеющее два параметра threshold и polarity\n",
        "\n",
        "![stump.png](data:image/png;base64,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)\n",
        "\n",
        "Классификатор работает следующим образом. На вход поступает одно число x, если x \\* polarity >= threshold \\* polarity, то классификатор возвращает 1, иначе 0. polarity равно либо 1 либо -1 и задает знак неравенства между threshold и x.\n",
        "\n",
        "Чтобы обучить такой классификатор нам необходимо выбрать оптимальную точку разделения, минимизирующую количество мисклассификаций, взвешенных с помощью весов, полученных на очередном раунде бустинга\n",
        "\n",
        "$$\n",
        "\\epsilon = \\sum_i w_i |h_j(x_i) - y_i|\n",
        "$$\n",
        "\n",
        "\n",
        "Идея алгоритма следующая:\n",
        "\n",
        "Пусть $w$ -- массив весов примеров, упорядоченных по значению признаков. Считаем, что все примеры имеют разное значение признака x. Если порог стоит в примере i, и polarity = 1, то функция потерь будет равна\n",
        "\n",
        "$$\n",
        "\\epsilon = \\sum_{j=1}^{i-1} w_j [y_j=1] + \\sum_{j=i}^n w_j [y_j=0]\n",
        "$$\n",
        "\n",
        "[сумма весов всех примеров класса 1 строго слева от порога] + [сумма весов всех примеров класса 0 справа от порога(включая пример, в котором установлен порог)]\n",
        "\n",
        "Допустим, мы знаем эти суммы (они называются кумулятивными), для всех возможных значений порога. Тогда, нужно просто сложить их и выбрать наименьшую.\n",
        "\n",
        "Пример:\n",
        "\n",
        "w = [2, 2, 2, 2, 2]\n",
        "\n",
        "y = [0, 1, 0, 1, 1]\n",
        "\n",
        "x = [1, 2, 3, 4, 5]\n",
        "\n",
        "Если порог находится в x = 1\n",
        "\n",
        "error = () + (2 + 2) т.к. слева от 1 нет ничего, а справа два неправильно классифицированных ноля веса 2\n",
        "\n",
        "Сдвигаем порог вправо в x = 2\n",
        "\n",
        "error = () + (2) т.к. слева нет единиц, а справа один ноль\n",
        "\n",
        "Сдвигаем на x = 3\n",
        "\n",
        "error = (2) + (2) т.к. слева одна единица, а справа один ноль\n",
        "\n",
        "и т.д.\n",
        "\n",
        "Можно в явном виде выписать все кумулятивные суммы\n",
        "\n",
        "Сумма весов объектов класса один слева, если порог = x[i] \n",
        "\n",
        "s1 = [0, 0, 2, 2, 4]\n",
        "\n",
        "Сумма весов объектов класса ноль справа, если порог = x[i] \n",
        "\n",
        "s2 = [4, 2, 2, 0, 0]\n",
        "\n",
        "Заметим, что ошибка в позиции x[i] = s2[i] + s1[i] и оптимум лежит в позиции 2, с ошибкой = 2\n",
        "\n",
        "Хотя второй вариант выглядит медленнее, он может быть эффективнее, если воспользоваться векторизованными примитивами numpy.  \n",
        "\n",
        "Нужным примитивом является numpy.cumsum, реализуйте алгоритм с его помощью. Не забудьте, что нужно также посчитать оптимальный порог для polarity = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e3dc75e-c43a-4cfd-9112-4473ec403456",
      "metadata": {
        "tags": [],
        "id": "9e3dc75e-c43a-4cfd-9112-4473ec403456"
      },
      "outputs": [],
      "source": [
        "class DecisionStump:\n",
        "    def __init__(self, threshold = 0, polarity = 1):\n",
        "        self.threshold = threshold\n",
        "        self.polarity = polarity\n",
        "        \n",
        "    def train(self, X, y, w, indices):\n",
        "        '''\n",
        "            Функция осуществляет обучение слабого классификатора\n",
        "            \n",
        "            На входе:\n",
        "                X -- одномерный отсортированный numpy массив со значениями признака\n",
        "                y -- одномерный numpy массив со значением класса для примера (0|1)\n",
        "                Порядок y -- до сортировки X\n",
        "                w -- одномерный numpy массив со значением весов признаков\n",
        "                Порядок w -- до сортировки X\n",
        "                indices -- одномерный numpy массив, перестановка [несортированный X] -> [сортированный X]\n",
        "                Массив indices нужен для оптимизации,\n",
        "                чтобы не сортировать X каждый раз, мы предсортируем значения признаков\n",
        "                для всех примеров. При этом мы сохраняем отображение между сортированными\n",
        "                и изначальными индексами, чтобы знать соответствие между x, y и w\n",
        "\n",
        "                indices[i] == изначальный индекс элемента, i-го в порядке сортировки\n",
        "            \n",
        "            На выходе:\n",
        "            \n",
        "            численное значение ошибки обученного классификатора\n",
        "        '''\n",
        "                \n",
        "        w = np.take(w, indices)\n",
        "        y = np.take(y, indices)\n",
        "        \n",
        "        #TODO\n",
        "        l = list(map(get_error, [(X, w, y, 1), (X, w, y, -1)]))\n",
        "        error, self.threshold, self.polarity = l[0] if l[0][0] < l[1][0] else l[1]\n",
        "        return error\n",
        "            \n",
        "    def classify(self, x):\n",
        "        #TODO\n",
        "        return x * self.polarity >= self.threshold * self.polarity\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return \"Threshold: {}, polarity: {}\".format(self.threshold, self.polarity)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_error(args):\n",
        "    X, w, y, polarity = args\n",
        "    if polarity == 1:\n",
        "        s1 = np.concatenate((np.array([0]), np.cumsum(w * y)[:-1]))\n",
        "        s2 = np.cumsum(w[::-1] * (1 - y)[::-1])[::-1]\n",
        "        errors = s1 + s2\n",
        "        i = np.argmin(errors)\n",
        "        return errors[i], X[i], polarity\n",
        "    else:\n",
        "        s1 = np.concatenate((np.array([0]), np.cumsum(w * (1 - y))[:-1]))\n",
        "        s2 = np.cumsum((w * y)[::-1])[::-1]\n",
        "        errors = s1 + s2\n",
        "        i = np.argmin(errors)\n",
        "        return errors[i], X[i - 1], polarity"
      ],
      "metadata": {
        "id": "2qRssak2HLuQ"
      },
      "id": "2qRssak2HLuQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f4c81f4b-b573-45a2-b56a-f4e66090edd1",
      "metadata": {
        "id": "f4c81f4b-b573-45a2-b56a-f4e66090edd1"
      },
      "source": [
        "## Протестируем базовый классификатор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c39d3dc-3e57-4589-b724-3bdae584e374",
      "metadata": {
        "id": "5c39d3dc-3e57-4589-b724-3bdae584e374"
      },
      "outputs": [],
      "source": [
        "classifier1 = DecisionStump(1, 1)\n",
        "\n",
        "assert(classifier1.classify(1) == 1)\n",
        "assert(classifier1.classify(10) == 1)\n",
        "assert(classifier1.classify(0) == 0)\n",
        "assert((classifier1.classify(np.array([1, 0, 10])) == np.array([1, 0, 1])).all())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c7dd9e8-f1e7-4270-9cb7-3c4cfdb07bf8",
      "metadata": {
        "id": "2c7dd9e8-f1e7-4270-9cb7-3c4cfdb07bf8"
      },
      "outputs": [],
      "source": [
        "classifier = DecisionStump()\n",
        "X = np.asarray([0, 1, 2, 3, 4])\n",
        "y = np.asarray([0, 0, 1, 1, 1])\n",
        "w = np.asarray([1, 1, 1, 1, 1])\n",
        "error = classifier.train(X, y, w, [0, 1, 2, 3, 4])\n",
        "assert(error == 0.0)\n",
        "assert(classifier.threshold > 1 and classifier.threshold <= 2 and classifier.polarity == 1)\n",
        "\n",
        "classifier = DecisionStump()\n",
        "X = np.asarray([0, 1, 2, 3, 4])\n",
        "y = np.asarray([0, 0, 1, 1, 1])\n",
        "w = np.asarray([1, 1, 1, 1, 1])\n",
        "error = classifier.train(X, y, w, [0, 1, 2, 3, 4])\n",
        "assert(error == 0.0)\n",
        "assert(classifier.threshold > 1 and classifier.threshold <= 2 and classifier.polarity == 1)\n",
        "\n",
        "classifier = DecisionStump()\n",
        "X = np.asarray([0, 1, 2, 3, 4])\n",
        "y = np.asarray([1, 1, 0, 0, 0])\n",
        "w = np.asarray([1, 1, 1, 1, 1])\n",
        "error = classifier.train(X, y, w, [0, 1, 2, 3, 4])\n",
        "assert(error == 0.0)\n",
        "assert(classifier.threshold >= 1 and classifier.threshold < 2 and classifier.polarity == -1)\n",
        "\n",
        "classifier = DecisionStump()\n",
        "X = np.asarray([0, 1, 2, 3, 4])\n",
        "y = np.asarray([0, 1, 0, 1, 1])\n",
        "w = np.asarray([1, 1, 10, 1, 1])\n",
        "error = classifier.train(X, y, w, [0, 1, 2, 3, 4])\n",
        "assert(error == 1.0)\n",
        "assert(classifier.threshold > 2 and classifier.threshold <= 3 and classifier.polarity == 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "745e73d2-4b2b-477c-8236-e80ae03cdf61",
      "metadata": {
        "tags": [],
        "id": "745e73d2-4b2b-477c-8236-e80ae03cdf61"
      },
      "source": [
        "## Тренировка базового классификатора на всех признаках и выбор лучшего\n",
        "\n",
        "Сейчас, когда мы умеем тренировать слабый классификатор, необходимо найти лучший слабый классификатор по всем признакам. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d83ff15-a9a2-4407-84d6-0edbf609b326",
      "metadata": {
        "tags": [],
        "id": "7d83ff15-a9a2-4407-84d6-0edbf609b326"
      },
      "outputs": [],
      "source": [
        "def train_classifier(classifier_type, X, y, w, indices):\n",
        "    classifier = classifier_type()\n",
        "    error = classifier.train(X, y, w, indices)\n",
        "    return error, classifier\n",
        "\n",
        "def learn_best_classifier(classifier_type, X, y, w, indices):\n",
        "    '''\n",
        "    Функция находит лучший слабый классификатор\n",
        "    \n",
        "    На входе:\n",
        "        classifier_type -- класс классификатора (DecisionStump в нашем случае)\n",
        "        X -- двумерный numpy массив, где X[i, j] -- значение признака i для примера j\n",
        "        Каждый X[i] отсортирован по возрастанию\n",
        "        y -- одномерный numpy массив с классом объекта (0|1). Порядок y соответствует порядку примеров в датасете\n",
        "        w -- одномерный numpy массив весов для каждого примера. Порядок w соответствует порядку примеров в датасете\n",
        "        indices -- список одномерных numpy массивов. \n",
        "        indices[i, j] == изначальный индекс элемента, j-го в порядке сортировки для i-го признака\n",
        "        \n",
        "    На выходе:\n",
        "        best_classifier -- лучший слабый классификатор\n",
        "        best_error -- его ошибка\n",
        "        best_feature_ind -- номер признака, на котором он был обучен (одна из HaarFeatures)\n",
        "        predictions -- предсказания классификатора (в порядке до сортировки)\n",
        "    '''\n",
        "    best_error = 1e10\n",
        "    best_classifier = None\n",
        "    best_feature_ind = None\n",
        "\n",
        "    features_count = X.shape[1]\n",
        "    errors = np.zeros(features_count)\n",
        "    classifiers = [None] * features_count\n",
        "    \n",
        "    #TODO\n",
        "    # натренируем каждый классификатор по каждому признаку\n",
        "    for i in range(0, features_count):\n",
        "        errors[i], classifiers[i] = train_classifier(classifier_type, X[i], y, w, indices[i])\n",
        "        if errors[i] < best_error:\n",
        "            best_error = errors[i]\n",
        "            best_classifier = classifiers[i]\n",
        "            best_feature_ind = i\n",
        "    \n",
        "\n",
        "    # выберем наилучший и сохраним лучший классификатор, ошибку, признак и индекс признака в \n",
        "    # best_classifier, best_error, best_feature, best_feature_ind   \n",
        "    return best_classifier, best_error, best_feature_ind"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}